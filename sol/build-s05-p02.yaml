spack:
  # CUSTOM MODULES
  # these modifications blacklist the system compiler to make Core packages
  # this streamlines the lmod tree that we expose to the users
  # dev: could have sworn you could not set this, but now it is required or else
  #   we have collisions
  view: false
  concretizer: 
    # beware the concretizer settings have implications for reproducibility
    #   and setting them to avoid duplication may cause hashes to change
    #   for no reason, for example, when the install_root changes. the 
    #   use of these settings might be a red herring. trust the process
    # # for the middleware we use the most aggressive settings while
    # #   we dial in the packages. then we relax unify to get two copies
    # #   of the osu-micro-benchmarks
    # unify: false
    # reuse: true
    # duplicates:
    #   strategy: none
    unify: when_possible
    reuse: false
  modules:
    # configurations for a module set
    default:
      roots:
        lmod: $SPACK_ENV/lmod
      arch_folder: false
      lmod:
        core_compilers:
        - &gcc_back !system_compiler
        hierarchy:
        - compiler
        - mpi
        exclude:
        - !cat ['%', *gcc_back]
        - lmod
        include:
        - gcc
        - openmpi
        - intel-oneapi-compilers
        - intel-oneapi-mpi
        exclude_implicits: true
        projections:
          all: '{name}/{version}'
          'openmpi fabrics=none': '{name}-intra/{version}'
        hash_length: 0
  config:
    # pack the install root with the superspec
    install_tree:
      root: /share/Apps/build/ice24v2/marianatrenchbuildsite
    build_stage:
    - $TMPDIR
  # EXTERNAL packages
  packages:
    slurm:
      buildable: false
      externals:
      - spec: slurm@23.02.8 
        prefix: /usr/local/slurm
    hcoll:
      buildable: false
      externals:
      - spec: hcoll@4.8.3230
        prefix: /opt/mellanox/hcoll
    gcc:
      buildable: false
      externals:
        - prefix: /share/Apps/ice24v2/gcc-11.5.0/gcc-12.4.0-wf7cn26kms2d4zw2tzn64b3n7rh26dil
          spec: gcc@12.4.0%gcc@11.5.0~binutils+bootstrap~graphite~mold~nvptx~piclibs~profiled~strip build_system=autotools build_type=RelWithDebInfo languages='c,c++,fortran' arch=linux-almalinux9-icelake
          extra_attributes:
            compilers:
              c: /share/Apps/ice24v2/gcc-11.5.0/gcc-12.4.0-wf7cn26kms2d4zw2tzn64b3n7rh26dil/bin/gcc
              cxx: /share/Apps/ice24v2/gcc-11.5.0/gcc-12.4.0-wf7cn26kms2d4zw2tzn64b3n7rh26dil/bin/g++
              fortran: /share/Apps/ice24v2/gcc-11.5.0/gcc-12.4.0-wf7cn26kms2d4zw2tzn64b3n7rh26dil/bin/gfortran
    intel-oneapi-compilers:
      buildable: false
      externals:
        - prefix: /share/Apps/ice24v2/gcc-11.5.0/intel-oneapi-compilers-2025.0.0-jnx4zlxhuwxa3ydvxb2odytep3xv5tgu
          spec: intel-oneapi-compilers@2025.0.0%gcc@11.5.0~amd+envmods~nvidia build_system=generic arch=linux-almalinux9-icelake
          extra_attributes:
            compilers:
              c: /share/Apps/ice24v2/gcc-11.5.0/intel-oneapi-compilers-2025.0.0-jnx4zlxhuwxa3ydvxb2odytep3xv5tgu/compiler/2025.0/bin/icx
              cxx: /share/Apps/ice24v2/gcc-11.5.0/intel-oneapi-compilers-2025.0.0-jnx4zlxhuwxa3ydvxb2odytep3xv5tgu/compiler/2025.0/bin/icpx
              fortran: /share/Apps/ice24v2/gcc-11.5.0/intel-oneapi-compilers-2025.0.0-jnx4zlxhuwxa3ydvxb2odytep3xv5tgu/compiler/2025.0/bin/ifx
  # specs in a superspec format, using list of lists
  # GCC + MPI
  specs: !flatten
  - - - !cat
        - &gcc gcc@12.4.0
        - !spec {compiler: *gcc_back}
        - &arch arch=linux-almalinux9-icelake
    - !compiled
      compiler: *gcc 
      arch: *arch
      specs: 
      - !cat
        - lmod@8.7.37 auto_swap=true build_system=autotools  
    # gcc CUDA and ucx for openmpi
    - !compiled
      compiler: !cat [*gcc, *arch]
      specs:
      - &cuda cuda@12.6.2 +allow-unsupported-compilers
      # deprecated but reserved for later
      # - &cmake cmake@3.30.5 ~qtgui ^curl +libidn2
      - &ucx !cat
        # opt-in to cma, dc, dm, ib_hw_tm, mlx5_dv, rc, thread_multiple, ud, verbs
        # opt-in to knem, xpmem after ensuring kernel modules are installed (via hpcx)
        - ucx@1.18.0
          ~assertions
          ~backtrace_detail
          +cma
          +cuda
          +dc
          ~debug
          +dm
          +examples
          +gdrcopy
          ~gtest
          +ib_hw_tm
          ~java
          +knem
          ~logging
          +mlx5_dv
          +openmp
          +optimizations
          ~parameter_checking
          +pic
          +rc
          +rdmacm
          ~rocm
          +thread_multiple
          ~ucg
          +ud
          +verbs
          ~vfs
          +xpmem 
          build_system=autotools
          libs=shared,static
          opt=3 
          simd=auto 
          cuda_arch=75,80,86,89
        - !spec {depends: *cuda}
        # note that we discarded hwloc +cuda from previous versions
        # restrain man_pages because it requires cmake +qtgui 
        - !spec {depends: rdma-core ~man_pages}
        - !spec
          depends: &xpmem xpmem@20241230 ~kernel-module
        - !spec
          depends: &knem knem@20241230
    # hwloc and libevent
    - !compiled
      compiler: *gcc
      specs: 
      - !cat
        - &hwloc 
          hwloc@2.11.1 
          +cuda +pci +libxml2
          cuda_arch=75,80,86,89
        - !spec {depends: *cuda}
      - &libevent libevent@2.1.12
    # mpi: openmpi 5
    - - &ompi5 !cat
        - !cat
          - &ompi-base openmpi@5.0.5
          - !spec {compiler: *gcc}
          #! PENDING fabrics. previously: fabrics=cma,hcoll,knem,ucx,xpmem
          #!   note that we are waiting on hcoll possibly needs to be installed everywhere? and knem and xpmem
          #!   note also that ucx covers a lot of the transport layers, perhaps all of them
          - &ompi-variants 
            +atomics 
            +cuda 
            ~debug 
            ~gpfs
            ~internal-hwloc 
            ~internal-libevent 
            ~internal-pmix
            ~java 
            ~lustre 
            ~memchecker
            +openshmem 
            +romio 
            +rsh 
            ~static 
            ~two_level_namespace
            +vt 
            +wrapper-rpath
            build_system=autotools
            fabrics=cma,ucx,knem,xpmem,hcoll
            schedulers=slurm
            cuda_arch=75,80,86,89
          - *arch
        - !spec {depends: *ucx}
        - !spec {depends: *hwloc}
        - !spec {depends: *libevent}
        - !spec {depends: *cuda}
        - !spec {depends: *xpmem}
        - !spec {depends: *knem}
    # include microbenchmarks with the MPI build-s03-p02.yaml stage for quick testing
    - - !cat
        - osu-micro-benchmarks@7.4
        - !spec {depends: *ompi5}
  # INTEL + MPI
  # note that I installed the compilers at one version and oneapi is detected at another
  - - - !cat
        - &intel-compiler intel-oneapi-compilers@2025.0.0
        - *arch
        - !spec {compiler: *gcc_back}
    - - &intel-mpi !cat
        - !cat
          - &intel-mpi-base intel-oneapi-mpi@2021.12.1
          - !spec 
            compiler: &intel oneapi@2025.0.0
          - &intel-mpi-variants 
            +envmods ~external-libfabric ~generic-names ~ilp64 
            build_system=generic 
          - *arch
    # Intel CUDA 
    - !compiled
      compiler: !cat [*intel, *arch]
      specs:
      - &cuda cuda@12.6.2
    # include microbenchmarks with the MPI build-s03-p02.yaml stage for quick testing
    - - !cat
        - osu-micro-benchmarks@7.4
        # no idea why we have to specify intel here but it seems to try gcc otherwise
        - !spec {compiler: *intel}
        - !spec {depends: *intel-mpi}
